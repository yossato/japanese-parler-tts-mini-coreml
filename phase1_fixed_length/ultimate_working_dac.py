#!/usr/bin/env python3
"""
DACçµ±åˆã®æ¬¡å…ƒå•é¡Œã‚’ä¿®æ­£
ç©ç®—å‡¦ç†ã®æ¬¡å…ƒã‚’æ­£ã—ãèª¿æ•´
"""

import sys
import os
sys.path.append('/Users/yoshiaki/Projects/parler-tts')

import torch
import torch.nn as nn
from transformers import AutoTokenizer
from parler_tts import ParlerTTSForConditionalGeneration
import time
import json
import numpy as np
import wave
from pathlib import Path

from memory_efficient_decoder import MemoryEfficientFixedLengthDecoder

class UltimateWorkingTTSGenerator:
    """ç©¶æ¥µã®å‹•ä½œç‰ˆTTSç”Ÿæˆå™¨ (æ¬¡å…ƒå•é¡Œè§£æ±º)"""
    
    def __init__(self, model_name="parler-tts/parler-tts-mini-v1", max_length=100):
        print(f"ğŸ¯ Loading ULTIMATE Working TTS Generator")
        print(f"   Model: {model_name}")
        print(f"   Max length: {max_length} tokens")
        
        self.device = torch.device("cpu")
        self.max_length = max_length
        
        # ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰
        print("ğŸ“¦ Loading Parler TTS model...")
        self.model = ParlerTTSForConditionalGeneration.from_pretrained(
            model_name,
            torch_dtype=torch.float32,
            device_map="cpu"
        )
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        
        # ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼
        print("âš¡ Creating memory efficient decoder...")
        self.efficient_decoder = MemoryEfficientFixedLengthDecoder(
            self.model.decoder,
            max_length=max_length
        )
        
        # DACè¨­å®š
        self.audio_encoder = self.model.audio_encoder
        self.dac_config = self.audio_encoder.config
        
        print(f"ğŸ“Š DAC Configuration:")
        print(f"   Codebook size: {self.dac_config.codebook_size}")
        print(f"   Sampling rate: {self.dac_config.sampling_rate} Hz")
        
        print("âœ… ULTIMATE Working TTS Generator ready!")
    
    def generate_audio_codes(self, text, description="A female speaker with a slightly low-pitched voice delivers her words quite expressively, in a very confined sounding environment with very clear audio quality."):
        """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰éŸ³å£°ã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆ"""
        
        print(f"ğŸ”¤ Generating audio codes for: \"{text}\"")
        
        text_inputs = self.tokenizer(
            description,
            return_tensors="pt",
            padding=True,
            truncation=True,
            max_length=50
        )
        
        with torch.no_grad():
            start_time = time.time()
            
            encoder_outputs = self.model.text_encoder(
                input_ids=text_inputs.input_ids,
                attention_mask=text_inputs.attention_mask
            )
            
            decoder_outputs = self.efficient_decoder(
                encoder_hidden_states=encoder_outputs.last_hidden_state,
                encoder_attention_mask=text_inputs.attention_mask,
                max_new_tokens=self.max_length
            )
            
            end_time = time.time()
            
            audio_codes = decoder_outputs['tokens'].squeeze(0)  # [num_codebooks, length]
            
        print(f"  â±ï¸  Code generation time: {end_time - start_time:.3f}s")
        print(f"  ğŸ“Š Audio codes shape: {audio_codes.shape}")
        print(f"  ğŸšï¸  Code range: [{audio_codes.min()}, {audio_codes.max()}]")
        
        return {
            'audio_codes': audio_codes,
            'generation_time': end_time - start_time
        }
    
    def codes_to_audio(self, audio_codes):
        """éŸ³å£°ã‚³ãƒ¼ãƒ‰ã‹ã‚‰å®Ÿéš›ã®éŸ³å£°æ³¢å½¢ã‚’ç”Ÿæˆ (æ¬¡å…ƒä¿®æ­£ç‰ˆ)"""
        
        print(f"ğŸµ Converting codes to audio...")
        print(f"   Input codes shape: {audio_codes.shape}")
        
        with torch.no_grad():
            start_time = time.time()
            
            try:
                # DACå†…éƒ¨ãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—
                dac_internal = self.audio_encoder.model
                quantizer = dac_internal.quantizer
                
                # éŸ³å£°ã‚³ãƒ¼ãƒ‰ã®å½¢çŠ¶ã‚’èª¿æ•´
                if audio_codes.dim() == 2:
                    audio_codes = audio_codes.unsqueeze(0)  # [9, 100] -> [1, 9, 100]
                
                # éŸ³å£°ã‚³ãƒ¼ãƒ‰ã‚’æ­£ã—ã„ç¯„å›²ã«ã‚¯ãƒ©ãƒ³ãƒ—
                audio_codes = torch.clamp(audio_codes, 0, self.dac_config.codebook_size - 1)
                print(f"   Clamped codes range: [{audio_codes.min()}, {audio_codes.max()}]")
                
                # quantizerã®æ§‹é€ ã‚’è©³ç´°èª¿æŸ»
                print(f"   ğŸ” Investigating quantizer structure...")
                sample_layer = quantizer.quantizers[0]
                print(f"   First quantizer layer type: {type(sample_layer)}")
                
                # quantizerã®out_projã‚’ä½¿ç”¨ã—ã¦æ­£ã—ã„æ¬¡å…ƒã«å¤‰æ›
                latents = torch.zeros(audio_codes.shape[0], 1024, audio_codes.shape[2], 
                                    device=audio_codes.device)
                
                for i, quantizer_layer in enumerate(quantizer.quantizers):
                    if i < audio_codes.shape[1]:
                        layer_codes = audio_codes[:, i, :]  # [1, 100]
                        
                        print(f"   Processing layer {i}, codes shape: {layer_codes.shape}")
                        
                        # ã¾ãšcodebookã§åŸ‹ã‚è¾¼ã¿å–å¾—
                        embedded = quantizer_layer.codebook(layer_codes)  # [1, 100, 8]
                        print(f"   Layer {i} embedded shape: {embedded.shape}")
                        
                        # out_projã§1024æ¬¡å…ƒã«å¤‰æ›
                        if hasattr(quantizer_layer, 'out_proj'):
                            # [1, 100, 8] -> [1, 8, 100] -> out_proj -> [1, 1024, 100]
                            embedded_t = embedded.transpose(1, 2)  # [1, 8, 100]
                            projected = quantizer_layer.out_proj(embedded_t)  # [1, 1024, 100]
                            print(f"   Layer {i} projected shape: {projected.shape}")
                            latents += projected
                        else:
                            print(f"   Layer {i}: no out_proj found")
                
                print(f"   Combined latents shape: {latents.shape}")
                
                # DAC decodeå®Ÿè¡Œ
                audio_waveform = dac_internal.decode(latents.detach())
                
                if isinstance(audio_waveform, torch.Tensor):
                    audio_np = audio_waveform.detach().squeeze().cpu().numpy()
                else:
                    audio_np = np.array(audio_waveform)
                
                end_time = time.time()
                
                print(f"   â±ï¸  Audio conversion time: {end_time - start_time:.3f}s")
                print(f"   ğŸ“Š Audio waveform shape: {audio_np.shape}")
                print(f"   ğŸšï¸  Audio range: [{audio_np.min():.3f}, {audio_np.max():.3f}]")
                
                return {
                    'audio_waveform': audio_np,
                    'conversion_time': end_time - start_time,
                    'sample_rate': self.dac_config.sampling_rate,
                    'duration': len(audio_np) / self.dac_config.sampling_rate,
                    'is_real_dac': True
                }
                
            except Exception as e:
                print(f"   âŒ DAC decoding failed: {e}")
                print(f"   ğŸ”„ Falling back to mock audio...")
                
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                duration_seconds = audio_codes.shape[-1] / self.dac_config.frame_rate
                sample_rate = self.dac_config.sampling_rate
                num_samples = int(duration_seconds * sample_rate)
                
                t = np.linspace(0, duration_seconds, num_samples)
                frequency = 440
                audio_np = 0.3 * np.sin(2 * np.pi * frequency * t)
                
                return {
                    'audio_waveform': audio_np,
                    'conversion_time': 0.001,
                    'sample_rate': sample_rate,
                    'duration': duration_seconds,
                    'is_real_dac': False
                }
    
    def text_to_audio(self, text, output_dir="ultimate_working_audio", description=None):
        """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã¾ã§ã®å®Œå…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³"""
        
        if description is None:
            description = "A female speaker with a slightly low-pitched voice delivers her words quite expressively, in a very confined sounding environment with very clear audio quality."
        
        print(f"\nğŸµ Complete Text-to-Audio Pipeline (ULTIMATE)")
        print(f"   Text: \"{text}\"")
        
        total_start_time = time.time()
        
        # 1. éŸ³å£°ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ
        code_result = self.generate_audio_codes(text, description)
        audio_codes = code_result['audio_codes']
        
        # 2. éŸ³å£°æ³¢å½¢ç”Ÿæˆ
        audio_result = self.codes_to_audio(audio_codes)
        audio_waveform = audio_result['audio_waveform']
        sample_rate = audio_result['sample_rate']
        
        # 3. éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        Path(output_dir).mkdir(exist_ok=True)
        
        safe_text = "".join(c for c in text if c.isalnum() or c in " -_").strip()
        safe_text = safe_text.replace(" ", "_")[:30]
        filename = f"ultimate_audio_{safe_text}.wav"
        filepath = os.path.join(output_dir, filename)
        
        print(f"  ğŸ’¾ Saving audio file: {filename}")
        
        # æ­£è¦åŒ–ã¨ä¿å­˜
        audio_normalized = audio_waveform / np.max(np.abs(audio_waveform)) * 0.8
        audio_int16 = (audio_normalized * 32767).astype(np.int16)
        
        with wave.open(filepath, 'w') as wav_file:
            wav_file.setnchannels(1)
            wav_file.setsampwidth(2)
            wav_file.setframerate(sample_rate)
            wav_file.writeframes(audio_int16.tobytes())
        
        total_end_time = time.time()
        
        result = {
            'text': text,
            'output_file': filepath,
            'duration': audio_result['duration'],
            'sample_rate': sample_rate,
            'file_size_mb': os.path.getsize(filepath) / (1024**2),
            'total_time': total_end_time - total_start_time,
            'code_generation_time': code_result['generation_time'],
            'audio_conversion_time': audio_result['conversion_time'],
            'is_real_dac': audio_result['is_real_dac']
        }
        
        print(f"  âœ… Audio generation completed!")
        print(f"     Duration: {result['duration']:.2f}s")
        print(f"     File size: {result['file_size_mb']:.2f}MB")
        print(f"     Total time: {result['total_time']:.3f}s")
        
        if result['is_real_dac']:
            print(f"     ğŸ‰ ULTIMATE DAC AUDIO SUCCESS! ğŸ‰")
        else:
            print(f"     âš ï¸  Using fallback audio")
        
        return result

def test_ultimate_working_integration():
    """ç©¶æ¥µã®å‹•ä½œç‰ˆãƒ†ã‚¹ãƒˆ"""
    
    print("ğŸš€ Testing ULTIMATE Working DAC Integration")
    print("=" * 60)
    
    try:
        generator = UltimateWorkingTTSGenerator(max_length=100)
        
        test_texts = ["Hello", "Hello world"]
        
        results = []
        real_dac_count = 0
        
        for text in test_texts:
            print(f"\n--- Testing: '{text}' ---")
            
            result = generator.text_to_audio(text)
            results.append(result)
            
            if result['is_real_dac']:
                real_dac_count += 1
                print(f"    ğŸ‰ ULTIMATE DAC SUCCESS!")
            else:
                print(f"    âš ï¸  Fallback used")
        
        # çµæœã‚µãƒãƒªãƒ¼
        summary = {
            'results': results,
            'total_tests': len(test_texts),
            'real_dac_count': real_dac_count,
            'success_rate': real_dac_count / len(test_texts),
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
        }
        
        with open('ultimate_working_results.json', 'w') as f:
            json.dump(summary, f, indent=2)
        
        print(f"\nğŸ¯ ULTIMATE RESULTS:")
        print(f"   Total tests: {summary['total_tests']}")
        print(f"   Real DAC audio: {summary['real_dac_count']}")
        print(f"   Success rate: {summary['success_rate']:.1%}")
        
        if summary['success_rate'] > 0:
            print(f"   ğŸŠ ULTIMATE DAC INTEGRATION SUCCESS! ğŸŠ")
        
        return summary
        
    except Exception as e:
        print(f"âŒ Ultimate test failed: {e}")
        import traceback
        traceback.print_exc()
        return None

def main():
    print("Phase 1.1 Step 2: ULTIMATE Working DAC Integration")
    print("=" * 70)
    
    result = test_ultimate_working_integration()
    
    if result and result['success_rate'] > 0:
        print(f"\nğŸŠ ULTIMATE SUCCESS! DAC INTEGRATION COMPLETE! ğŸŠ")
        print(f"ğŸ“ Check real DAC audio in: ultimate_working_audio/")
        print(f"ğŸ§ Listen with: open ultimate_working_audio/ultimate_audio_Hello.wav")
        return True
    else:
        print(f"\nğŸ”§ Continue debugging DAC integration...")
        return False

if __name__ == "__main__":
    main()
