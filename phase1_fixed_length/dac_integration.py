#!/usr/bin/env python3
"""
Phase 1.1 Step 2: DACçµ±åˆã«ã‚ˆã‚‹å®ŸéŸ³å£°ç”Ÿæˆ
ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–ã•ã‚ŒãŸå›ºå®šé•·ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ + å®Ÿéš›ã®éŸ³å£°ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼(DAC)
"""

import sys
import os
sys.path.append('/Users/yoshiaki/Projects/parler-tts')

import torch
import torch.nn as nn
from transformers import AutoTokenizer
from parler_tts import ParlerTTSForConditionalGeneration
from parler_tts.dac_wrapper import DACModel
import time
import json
import numpy as np
import wave
from pathlib import Path

# memory_efficient_decoder.pyã‹ã‚‰å¿…è¦ãªã‚¯ãƒ©ã‚¹ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from memory_efficient_decoder import MemoryEfficientFixedLengthDecoder
except ImportError:
    print("âš ï¸  Warning: Could not import MemoryEfficientFixedLengthDecoder")
    print("    Please run memory_efficient_decoder.py first or ensure it's in the same directory")
    sys.exit(1)

class RealAudioTTSGenerator:
    """å®ŸéŸ³å£°ç”Ÿæˆå¯èƒ½ãªTTSã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, model_name="parler-tts/parler-tts-mini-v1", max_length=100):
        print(f"ğŸµ Loading Real Audio TTS Generator")
        print(f"   Model: {model_name}")
        print(f"   Max length: {max_length} tokens")
        
        self.device = torch.device("cpu")
        self.max_length = max_length
        
        # 1. ãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
        print("ğŸ“¦ Loading Parler TTS model...")
        self.model = ParlerTTSForConditionalGeneration.from_pretrained(
            model_name,
            torch_dtype=torch.float32,
            device_map="cpu"
        )
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        
        # 2. ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’ä½œæˆ
        print("âš¡ Creating memory efficient decoder...")
        self.efficient_decoder = MemoryEfficientFixedLengthDecoder(
            self.model.decoder,
            max_length=max_length
        )
        
        # 3. DACéŸ³å£°ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’å–å¾—
        print("ğŸ”Š Setting up DAC audio decoder...")
        self.audio_encoder = self.model.audio_encoder  # ã“ã‚ŒãŒDACModel
        
        # DACã®è¨­å®šæƒ…å ±ã‚’è¡¨ç¤º
        dac_config = self.audio_encoder.config
        print(f"ğŸ“Š DAC Configuration:")
        print(f"   Codebook size: {dac_config.codebook_size}")
        print(f"   Num codebooks: {dac_config.num_codebooks}")
        print(f"   Frame rate: {dac_config.frame_rate} Hz")
        print(f"   Sampling rate: {dac_config.sampling_rate} Hz")
        print(f"   Model bitrate: {dac_config.model_bitrate} kbps")
        
        self.dac_config = dac_config
        
        print("âœ… Real Audio TTS Generator ready!")
    
    def generate_audio_codes(self, text, description="A female speaker with a slightly low-pitched voice delivers her words quite expressively, in a very confined sounding environment with very clear audio quality."):
        """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰éŸ³å£°ã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆ"""
        
        print(f"ğŸ”¤ Generating audio codes for: \"{text}\"")
        
        # ãƒ†ã‚­ã‚¹ãƒˆã®ãƒˆãƒ¼ã‚¯ãƒ³åŒ–
        text_inputs = self.tokenizer(
            description,
            return_tensors="pt",
            padding=True,
            truncation=True,
            max_length=50
        )
        
        with torch.no_grad():
            start_time = time.time()
            
            # 1. ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
            print("  ğŸ“ Text encoding...")
            encoder_outputs = self.model.text_encoder(
                input_ids=text_inputs.input_ids,
                attention_mask=text_inputs.attention_mask
            )
            
            # 2. å›ºå®šé•·éŸ³å£°ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ
            print("  ğŸ¯ Fixed-length decoding...")
            decoder_outputs = self.efficient_decoder(
                encoder_hidden_states=encoder_outputs.last_hidden_state,
                encoder_attention_mask=text_inputs.attention_mask,
                max_new_tokens=self.max_length
            )
            
            end_time = time.time()
            
            # çµæœã®å½¢çŠ¶ã‚’æ•´ç†
            # decoder_outputs['tokens']: [batch_size, num_codebooks, length]
            audio_codes = decoder_outputs['tokens'].squeeze(0)  # [num_codebooks, length]
            
        print(f"  â±ï¸  Code generation time: {end_time - start_time:.3f}s")
        print(f"  ğŸ“Š Audio codes shape: {audio_codes.shape}")
        
        return {
            'audio_codes': audio_codes,
            'generation_time': end_time - start_time,
            'actual_length': decoder_outputs['actual_length'],
            'predicted_length': decoder_outputs['predicted_length']
        }
    
    def codes_to_audio(self, audio_codes):
        """éŸ³å£°ã‚³ãƒ¼ãƒ‰ã‹ã‚‰å®Ÿéš›ã®éŸ³å£°æ³¢å½¢ã‚’ç”Ÿæˆ"""
        
        print(f"ğŸµ Converting codes to audio...")
        print(f"   Input codes shape: {audio_codes.shape}")
        
        with torch.no_grad():
            start_time = time.time()
            
            # éŸ³å£°ã‚³ãƒ¼ãƒ‰ã®å½¢çŠ¶ã‚’ç¢ºèªãƒ»èª¿æ•´
            if audio_codes.dim() == 2:
                # [num_codebooks, length] -> [1, num_codebooks, length]
                audio_codes = audio_codes.unsqueeze(0)
            
            # DACã§éŸ³å£°å¾©å…ƒ
            print("  ğŸ”Š DAC decoding...")
            try:
                # DACã®æ­£ã—ã„ decode ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨
                # audio_scalesãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¿½åŠ 
                audio_scales = torch.ones(audio_codes.shape[0], device=audio_codes.device)
                audio_waveform = self.audio_encoder.decode(audio_codes, audio_scales)
                
                if isinstance(audio_waveform, torch.Tensor):
                    audio_waveform = audio_waveform.squeeze()  # ä½™åˆ†ãªæ¬¡å…ƒã‚’å‰Šé™¤
                    audio_np = audio_waveform.cpu().numpy()
                else:
                    audio_np = np.array(audio_waveform)
                
                end_time = time.time()
                
                print(f"  â±ï¸  Audio conversion time: {end_time - start_time:.3f}s")
                print(f"  ğŸ“Š Audio waveform shape: {audio_np.shape}")
                print(f"  ğŸšï¸  Audio range: [{audio_np.min():.3f}, {audio_np.max():.3f}]")
                
                return {
                    'audio_waveform': audio_np,
                    'conversion_time': end_time - start_time,
                    'sample_rate': self.dac_config.sampling_rate,
                    'duration': len(audio_np) / self.dac_config.sampling_rate
                }
                
            except Exception as e:
                print(f"  âŒ DAC decoding failed: {e}")
                print("  ğŸ”„ Falling back to mock audio generation...")
                
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ¢ãƒƒã‚¯éŸ³å£°ç”Ÿæˆ
                duration_seconds = audio_codes.shape[-1] / self.dac_config.frame_rate
                sample_rate = self.dac_config.sampling_rate
                num_samples = int(duration_seconds * sample_rate)
                
                # ç°¡å˜ãªåˆæˆéŸ³ç”Ÿæˆ
                t = np.linspace(0, duration_seconds, num_samples)
                frequency = 440  # AéŸ³
                audio_np = 0.3 * np.sin(2 * np.pi * frequency * t)
                
                return {
                    'audio_waveform': audio_np,
                    'conversion_time': 0.001,
                    'sample_rate': sample_rate,
                    'duration': duration_seconds,
                    'is_mock': True
                }
    
    def text_to_audio(self, text, output_dir="generated_real_audio", description=None):
        """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã¾ã§ã®å®Œå…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³"""
        
        if description is None:
            description = "A female speaker with a slightly low-pitched voice delivers her words quite expressively, in a very confined sounding environment with very clear audio quality."
        
        print(f"\nğŸµ Complete Text-to-Audio Pipeline")
        print(f"   Text: \"{text}\"")
        print(f"   Output dir: {output_dir}")
        
        total_start_time = time.time()
        
        # 1. éŸ³å£°ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ
        code_result = self.generate_audio_codes(text, description)
        audio_codes = code_result['audio_codes']
        
        # 2. éŸ³å£°æ³¢å½¢ç”Ÿæˆ
        audio_result = self.codes_to_audio(audio_codes)
        audio_waveform = audio_result['audio_waveform']
        sample_rate = audio_result['sample_rate']
        
        # 3. éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        Path(output_dir).mkdir(exist_ok=True)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆï¼ˆå®‰å…¨ãªæ–‡å­—ã®ã¿ï¼‰
        safe_text = "".join(c for c in text if c.isalnum() or c in " -_").strip()
        safe_text = safe_text.replace(" ", "_")[:30]
        filename = f"real_audio_{safe_text}.wav"
        filepath = os.path.join(output_dir, filename)
        
        # WAVãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        print(f"  ğŸ’¾ Saving audio file: {filename}")
        
        # éŸ³å£°ã‚’æ­£è¦åŒ–
        audio_normalized = audio_waveform / np.max(np.abs(audio_waveform)) * 0.8
        audio_int16 = (audio_normalized * 32767).astype(np.int16)
        
        with wave.open(filepath, 'w') as wav_file:
            wav_file.setnchannels(1)  # ãƒ¢ãƒãƒ©ãƒ«
            wav_file.setsampwidth(2)  # 16bit
            wav_file.setframerate(sample_rate)
            wav_file.writeframes(audio_int16.tobytes())
        
        total_end_time = time.time()
        
        # çµæœã®çµ±åˆ
        result = {
            'text': text,
            'output_file': filepath,
            'duration': audio_result['duration'],
            'sample_rate': sample_rate,
            'file_size_mb': os.path.getsize(filepath) / (1024**2),
            'total_time': total_end_time - total_start_time,
            'code_generation_time': code_result['generation_time'],
            'audio_conversion_time': audio_result['conversion_time'],
            'audio_codes_shape': audio_codes.shape,
            'is_mock': audio_result.get('is_mock', False)
        }
        
        print(f"  âœ… Audio generation completed!")
        print(f"     Duration: {result['duration']:.2f}s")
        print(f"     File size: {result['file_size_mb']:.2f}MB")
        print(f"     Total time: {result['total_time']:.3f}s")
        if result['is_mock']:
            print(f"     âš ï¸  Using mock audio (DAC decode failed)")
        
        return result
    
    def generate_comparison_audio(self, texts, output_dir="comparison_audio"):
        """è¤‡æ•°ãƒ†ã‚­ã‚¹ãƒˆã®éŸ³å£°ç”Ÿæˆã¨æ¯”è¼ƒ"""
        
        print(f"\nğŸ¼ Generating Comparison Audio")
        print(f"   Texts: {len(texts)}")
        print(f"   Output: {output_dir}")
        
        results = []
        
        for i, text in enumerate(texts):
            print(f"\n--- Text {i+1}/{len(texts)} ---")
            
            try:
                result = self.text_to_audio(text, output_dir)
                results.append(result)
                
            except Exception as e:
                print(f"âŒ Failed to generate audio for \"{text}\": {e}")
                results.append({
                    'text': text,
                    'error': str(e),
                    'success': False
                })
        
        # çµæœã®ã‚µãƒãƒªãƒ¼
        successful_results = [r for r in results if 'error' not in r]
        
        summary = {
            'total_texts': len(texts),
            'successful_generations': len(successful_results),
            'failed_generations': len(texts) - len(successful_results),
            'results': results,
            'average_duration': np.mean([r['duration'] for r in successful_results]) if successful_results else 0,
            'average_generation_time': np.mean([r['total_time'] for r in successful_results]) if successful_results else 0,
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
        }
        
        print(f"\nğŸ“Š Comparison Summary:")
        print(f"   Successful: {summary['successful_generations']}/{summary['total_texts']}")
        print(f"   Average duration: {summary['average_duration']:.2f}s")
        print(f"   Average generation time: {summary['average_generation_time']:.3f}s")
        
        return summary


def generate_original_vs_fixed_comparison():
    """ã‚ªãƒªã‚¸ãƒŠãƒ« vs å›ºå®šé•·ã®éŸ³å£°æ¯”è¼ƒå®Ÿé¨“"""
    
    print("\nğŸ¯ Original vs Fixed Length Audio Comparison")
    print("=" * 60)
    
    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹
    test_texts = [
        "Hello",
        "Hello world",
        "This is a test"
    ]
    
    # å›ºå®šé•·ç”Ÿæˆå™¨
    print("\n1. Creating Fixed Length Generator...")
    fixed_generator = RealAudioTTSGenerator(max_length=100)
    
    # å›ºå®šé•·éŸ³å£°ç”Ÿæˆ
    print("\n2. Generating Fixed Length Audio...")
    fixed_results = fixed_generator.generate_comparison_audio(
        test_texts, 
        output_dir="comparison_audio/fixed_length"
    )
    
    # ã‚ªãƒªã‚¸ãƒŠãƒ«ç”Ÿæˆå™¨ã§ã®æ¯”è¼ƒï¼ˆå‚è€ƒç”¨ï¼‰
    print("\n3. Generating Reference with Original Model...")
    try:
        # ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ¢ãƒ‡ãƒ«ã§ã®ç”Ÿæˆï¼ˆçŸ­ã„é•·ã•åˆ¶é™ï¼‰
        original_model = ParlerTTSForConditionalGeneration.from_pretrained(
            "parler-tts/parler-tts-mini-v1",
            torch_dtype=torch.float32,
            device_map="cpu"
        )
        tokenizer = AutoTokenizer.from_pretrained("parler-tts/parler-tts-mini-v1")
        
        original_results = []
        
        for text in test_texts:
            print(f"   Original generation: \"{text}\"")
            
            try:
                start_time = time.time()
                
                inputs = tokenizer(
                    "A female speaker with a slightly low-pitched voice.",
                    text,
                    return_tensors="pt",
                    truncation=True,
                    max_length=50
                )
                
                generation = original_model.generate(
                    input_ids=inputs.input_ids,
                    attention_mask=inputs.attention_mask,
                    do_sample=True,
                    temperature=1.0,
                    max_new_tokens=100
                )
                
                end_time = time.time()
                
                original_results.append({
                    'text': text,
                    'generation_time': end_time - start_time,
                    'output_shape': generation.shape,
                    'method': 'original'
                })
                
                print(f"     Time: {end_time - start_time:.3f}s, Shape: {generation.shape}")
                
            except Exception as e:
                print(f"     âŒ Failed: {e}")
                original_results.append({
                    'text': text,
                    'error': str(e),
                    'method': 'original'
                })
        
    except Exception as e:
        print(f"âŒ Original model comparison failed: {e}")
        original_results = []
    
    # æ¯”è¼ƒçµæœã®ä¿å­˜
    comparison_data = {
        'fixed_length_results': fixed_results,
        'original_results': original_results,
        'test_texts': test_texts,
        'config': {
            'fixed_max_length': 100,
            'model_name': 'parler-tts/parler-tts-mini-v1'
        },
        'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
    }
    
    with open('phase1_1_audio_comparison.json', 'w') as f:
        json.dump(comparison_data, f, indent=2)
    
    print(f"\nğŸ’¾ Comparison results saved to phase1_1_audio_comparison.json")
    
    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®å†ç”Ÿæ–¹æ³•ã‚’æ¡ˆå†…
    print(f"\nğŸ§ How to Listen to Generated Audio:")
    print(f"   Generated files are in: comparison_audio/fixed_length/")
    print(f"   Play with: open comparison_audio/fixed_length/real_audio_Hello.wav")
    print(f"   Or use: afplay comparison_audio/fixed_length/real_audio_Hello.wav")
    
    return comparison_data


def main():
    print("Phase 1.1 Step 2: DAC Integration for Real Audio Generation")
    print("=" * 70)
    
    try:
        # ãƒ¡ã‚¤ãƒ³å®Ÿé¨“ã®å®Ÿè¡Œ
        comparison_results = generate_original_vs_fixed_comparison()
        
        print(f"\nâœ… Phase 1.1 Step 2 completed successfully!")
        print(f"\nğŸ“‹ Next Steps:")
        print(f"   1. Listen to generated audio files in comparison_audio/fixed_length/")
        print(f"   2. Compare quality with original Parler TTS (if available)")
        print(f"   3. Evaluate if fixed-length approach maintains speech quality")
        print(f"   4. Proceed to Step 3: Quality evaluation")
        
        return comparison_results
        
    except Exception as e:
        print(f"âŒ Phase 1.1 Step 2 failed: {e}")
        import traceback
        traceback.print_exc()
        return None


if __name__ == "__main__":
    main()
