#!/usr/bin/env python3
"""
Parler TTSã®å®Ÿéš›ã®DACä½¿ç”¨æ–¹æ³•ã‚’èª¿æŸ»
å…¬å¼ã®ç”Ÿæˆãƒ—ãƒ­ã‚»ã‚¹ã‹ã‚‰DACçµ±åˆã®æ­£ã—ã„æ–¹æ³•ã‚’å­¦ç¿’
"""

import os
import sys
import torch
import numpy as np

# ãƒ‘ã‚¹è¨­å®š
phase1_dir = "/Users/yoshiaki/Projects/parler_tts_experiment/phase1_fixed_length"
os.chdir(phase1_dir)
sys.path.insert(0, phase1_dir)
sys.path.append('/Users/yoshiaki/Projects/parler-tts')

from parler_tts import ParlerTTSForConditionalGeneration
from transformers import AutoTokenizer

def investigate_official_generation():
    """Parler TTSã®å…¬å¼ç”Ÿæˆãƒ—ãƒ­ã‚»ã‚¹ã‚’èª¿æŸ»"""
    
    print("ğŸ” Investigating Official Parler TTS Generation Process")
    print("=" * 60)
    
    # ãƒ¢ãƒ‡ãƒ«ã¨ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ãƒ­ãƒ¼ãƒ‰
    model = ParlerTTSForConditionalGeneration.from_pretrained(
        "parler-tts/parler-tts-mini-v1",
        torch_dtype=torch.float32,
        device_map="cpu"
    )
    tokenizer = AutoTokenizer.from_pretrained("parler-tts/parler-tts-mini-v1")
    
    # ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›æº–å‚™
    description = "A female speaker with a clear voice."
    text = "Hello world"
    
    inputs = tokenizer(description, text, return_tensors="pt", truncation=True, max_length=50)
    
    print(f"ğŸ“ Input text: '{text}'")
    print(f"ğŸ“ Description: '{description}'")
    print(f"ğŸ“Š Input shape: {inputs.input_ids.shape}")
    
    # å…¬å¼ç”Ÿæˆãƒ—ãƒ­ã‚»ã‚¹å®Ÿè¡Œï¼ˆçŸ­æ™‚é–“ã§ï¼‰
    print(f"\nğŸ”„ Running official generation process...")
    
    try:
        with torch.no_grad():
            # çŸ­ã„ç”Ÿæˆã§ãƒ†ã‚¹ãƒˆ
            generation = model.generate(
                input_ids=inputs.input_ids,
                attention_mask=inputs.attention_mask,
                do_sample=True,
                temperature=1.0,
                max_new_tokens=50  # çŸ­ãè¨­å®š
            )
        
        print(f"âœ… Official generation successful!")
        print(f"ğŸ“Š Generation shape: {generation.shape}")
        
        # ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã‚’åˆ†æ
        analyze_generated_codes(generation, model)
        
        return generation, model
        
    except Exception as e:
        print(f"âŒ Official generation failed: {e}")
        return None, model

def analyze_generated_codes(generation, model):
    """ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã‚’åˆ†æã—ã¦DACçµ±åˆã®ãƒ’ãƒ³ãƒˆã‚’å¾—ã‚‹"""
    
    print(f"\nğŸ”¬ Analyzing Generated Audio Codes")
    print("=" * 40)
    
    print(f"Raw generation shape: {generation.shape}")
    print(f"Raw generation dtype: {generation.dtype}")
    print(f"Raw generation range: [{generation.min()}, {generation.max()}]")
    
    # Parler TTSã®ãƒ‡ã‚³ãƒ¼ãƒ‰æ–¹æ³•ã‚’èª¿æŸ»
    dac_model = model.audio_encoder
    decoder_config = model.decoder.config
    
    print(f"\nğŸ“Š Model Configuration:")
    print(f"   Num codebooks: {decoder_config.num_codebooks}")
    print(f"   Vocab size: {decoder_config.vocab_size}")
    print(f"   DAC num codebooks: {dac_model.config.num_codebooks}")
    print(f"   DAC codebook size: {dac_model.config.codebook_size}")
    
    # ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã‚’DACç”¨ã«å¤‰æ›
    try:
        # Parler TTSã®ç”Ÿæˆçµæœã‚’codebookå½¢å¼ã«å¤‰æ›
        print(f"\nğŸ”„ Converting generated codes to DAC format...")
        
        # ç”Ÿæˆã•ã‚ŒãŸãƒˆãƒ¼ã‚¯ãƒ³ã‚’reshape
        # generation: [batch_size * num_codebooks, length] -> [batch_size, num_codebooks, length]
        batch_size = 1
        num_codebooks = decoder_config.num_codebooks
        seq_length = generation.shape[-1] // num_codebooks
        
        print(f"Calculated dimensions:")
        print(f"   Batch size: {batch_size}")
        print(f"   Num codebooks: {num_codebooks}")
        print(f"   Sequence length: {seq_length}")
        print(f"   Total tokens: {generation.shape[-1]}")
        
        if generation.shape[-1] % num_codebooks == 0:
            # æ­£ç¢ºã«åˆ†å‰²å¯èƒ½
            audio_codes = generation.view(batch_size, num_codebooks, seq_length)
            print(f"âœ… Reshaped to: {audio_codes.shape}")
            
            # DAC decodeã‚’è©¦è¡Œ
            test_dac_with_real_codes(audio_codes, dac_model)
        else:
            print(f"âš ï¸  Cannot evenly divide generation into codebooks")
            print(f"   Total tokens: {generation.shape[-1]}")
            print(f"   Num codebooks: {num_codebooks}")
            print(f"   Remainder: {generation.shape[-1] % num_codebooks}")
            
    except Exception as e:
        print(f"âŒ Code analysis failed: {e}")
        import traceback
        traceback.print_exc()

def test_dac_with_real_codes(audio_codes, dac_model):
    """å®Ÿéš›ã®ç”Ÿæˆã‚³ãƒ¼ãƒ‰ã§DACãƒ†ã‚¹ãƒˆ"""
    
    print(f"\nğŸ§ª Testing DAC with Real Generated Codes")
    print("=" * 50)
    
    print(f"Audio codes shape: {audio_codes.shape}")
    print(f"Audio codes dtype: {audio_codes.dtype}")
    print(f"Audio codes range: [{audio_codes.min()}, {audio_codes.max()}]")
    
    # æ§˜ã€…ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã§ãƒ†ã‚¹ãƒˆ
    patterns = [
        ("Direct", audio_codes),
        ("Squeezed", audio_codes.squeeze()),
        ("Float", audio_codes.float()),
        ("Clipped", torch.clamp(audio_codes, 0, 1023)),
    ]
    
    for pattern_name, codes in patterns:
        print(f"\n{pattern_name} pattern - Shape: {codes.shape}")
        try:
            batch_size = codes.shape[0] if codes.dim() >= 3 else 1
            audio_scales = torch.ones(batch_size, device=codes.device)
            
            result = dac_model.decode(codes, audio_scales)
            print(f"   âœ… Success! Output shape: {result.shape}")
            
            # éŸ³å£°ä¿å­˜ãƒ†ã‚¹ãƒˆ
            save_real_dac_audio(result, pattern_name)
            return codes, audio_scales, pattern_name
            
        except Exception as e:
            print(f"   âŒ Failed: {e}")
    
    print(f"\nâŒ All real code patterns failed")
    return None, None, None

def save_real_dac_audio(audio_waveform, pattern_name):
    """å®Ÿéš›ã®DACéŸ³å£°ã‚’ä¿å­˜"""
    
    try:
        import wave
        
        if isinstance(audio_waveform, torch.Tensor):
            audio_np = audio_waveform.squeeze().cpu().numpy()
        else:
            audio_np = np.array(audio_waveform)
        
        # æ­£è¦åŒ–
        if np.max(np.abs(audio_np)) > 0:
            audio_np = audio_np / np.max(np.abs(audio_np)) * 0.8
        
        filename = f"real_dac_audio_{pattern_name.lower()}.wav"
        sample_rate = 44100
        
        audio_int16 = (audio_np * 32767).astype(np.int16)
        
        with wave.open(filename, 'w') as wav_file:
            wav_file.setnchannels(1)
            wav_file.setsampwidth(2)
            wav_file.setframerate(sample_rate)
            wav_file.writeframes(audio_int16.tobytes())
        
        duration = len(audio_np) / sample_rate
        file_size = os.path.getsize(filename) / 1024
        
        print(f"   ğŸ“ Saved: {filename}")
        print(f"   Duration: {duration:.2f}s, Size: {file_size:.1f}KB")
        print(f"   ğŸ§ Play: open {filename}")
        
        return True
        
    except Exception as e:
        print(f"   âŒ Save failed: {e}")
        return False

def investigate_dac_internals():
    """DACã®å†…éƒ¨å‹•ä½œã‚’è©³ã—ãèª¿æŸ»"""
    
    print(f"\nğŸ”¬ Deep DAC Investigation")
    print("=" * 40)
    
    model = ParlerTTSForConditionalGeneration.from_pretrained(
        "parler-tts/parler-tts-mini-v1",
        torch_dtype=torch.float32,
        device_map="cpu"
    )
    
    dac_model = model.audio_encoder
    
    # DACå†…éƒ¨ã®quantizerã‚’èª¿æŸ»
    if hasattr(dac_model.model, 'quantizer'):
        quantizer = dac_model.model.quantizer
        print(f"ğŸ“Š Quantizer info:")
        print(f"   Type: {type(quantizer)}")
        print(f"   Num quantizers: {len(quantizer.quantizers) if hasattr(quantizer, 'quantizers') else 'unknown'}")
        
        # quantizer.decodeãƒ¡ã‚½ãƒƒãƒ‰ã‚’è©¦ã™
        if hasattr(quantizer, 'decode'):
            print(f"   Has decode method: âœ…")
            
            # ãƒ†ã‚¹ãƒˆç”¨ã®quantized codesä½œæˆ
            test_codes = torch.randint(0, 1024, (1, 9, 100))  # [batch, num_q, seq_len]
            
            try:
                # quantizerçµŒç”±ã§decode
                decoded = quantizer.decode(test_codes)
                print(f"   Quantizer decode success: {decoded.shape}")
                
                # decoderã«é€šã™
                if hasattr(dac_model.model, 'decoder'):
                    final_audio = dac_model.model.decoder(decoded)
                    print(f"   Final audio shape: {final_audio.shape}")
                    
                    save_real_dac_audio(final_audio, "quantizer_path")
                    return True
                    
            except Exception as e:
                print(f"   Quantizer decode failed: {e}")
    
    return False

def main():
    print("ğŸµ Parler TTS DAC Investigation")
    print("=" * 50)
    
    try:
        # 1. å…¬å¼ç”Ÿæˆãƒ—ãƒ­ã‚»ã‚¹èª¿æŸ»
        generation, model = investigate_official_generation()
        
        if generation is not None:
            print(f"\nâœ… Official generation analysis completed")
        else:
            print(f"\nâš ï¸  Official generation failed, trying alternative approach")
            
        # 2. DACå†…éƒ¨æ§‹é€ èª¿æŸ»
        print(f"\n" + "="*50)
        success = investigate_dac_internals()
        
        if success:
            print(f"\nğŸ¯ DAC integration method found!")
        else:
            print(f"\nâš ï¸  Still investigating DAC integration...")
            
    except Exception as e:
        print(f"âŒ Investigation failed: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
